{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10235161,"sourceType":"datasetVersion","datasetId":6328797}],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import MinMaxScaler, OneHotEncoder\nfrom sklearn.model_selection import StratifiedKFold, train_test_split\nfrom imblearn.over_sampling import SMOTE\nimport tensorflow as tf\nfrom tensorflow.keras import Input, Model\nfrom tensorflow.keras.layers import Dense, Dropout, BatchNormalization\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\nfrom sklearn.metrics import classification_report, accuracy_score\nimport joblib\nimport warnings\nimport shap\nimport matplotlib.pyplot as plt\n\n# Mengabaikan warning yang tidak perlu\nwarnings.filterwarnings('ignore')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-18T11:24:23.480098Z","iopub.execute_input":"2024-12-18T11:24:23.480722Z","iopub.status.idle":"2024-12-18T11:24:40.240781Z","shell.execute_reply.started":"2024-12-18T11:24:23.480685Z","shell.execute_reply":"2024-12-18T11:24:40.240039Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n\n# ---------------------------------------\n# LOAD DAN PERSIAPAN DATA\n# ---------------------------------------\n# Ganti path sesuai lokasi dataset Anda\ndf = pd.read_csv(\"/kaggle/input/dataset-pkm/dataset_Media_Bioflok.csv\")\n\n# Menampilkan beberapa baris awal untuk inspeksi\nprint(\"Contoh Data Awal:\")\nprint(df.head())\n\n# Menghapus kolom 'Timestamp' jika ada\nif 'Timestamp' in df.columns:\n    df = df.drop(['Timestamp'], axis=1)\n    print(\"Kolom 'Timestamp' telah dihapus.\")\n\n# ---------------------------------------\n# FEATURE ENGINEERING\n# ---------------------------------------\ndef combine_dimensions(row):\n    if row['Bentuk_Kolam'] == 'Bulat':\n        return row['Diameter (m)']\n    elif row['Bentuk_Kolam'] == 'Kotak':\n        return (row['Panjang (m)'] + row['Lebar (m)']) / 2\n    else:\n        return 0\n\ndf['Dimensi (m)'] = df.apply(combine_dimensions, axis=1)\n\n# Drop kolom yang tidak diperlukan lagi tanpa menggunakan inplace=True\ndf = df.drop(['Diameter (m)', 'Panjang (m)', 'Lebar (m)'], axis=1)\n\n# Isi nilai kosong jika ada tanpa menggunakan inplace=True\ndf['Tinggi (m)'] = df['Tinggi (m)'].fillna(df['Tinggi (m)'].mean())\n\n# Encoding kategorikal tanpa menggunakan inplace=True\ncategorical_features = ['Bentuk_Kolam', 'Material_Kolam']\nencoder = OneHotEncoder(sparse=False, drop='first')  # drop='first' untuk menghindari dummy variable trap\nencoded_categorical = encoder.fit_transform(df[categorical_features])\nencoded_feature_names = encoder.get_feature_names_out(categorical_features)\n\ndf_encoded = pd.DataFrame(encoded_categorical, columns=encoded_feature_names)\n\n# Reset index untuk memastikan konsistensi saat concat\ndf = df.reset_index(drop=True)\ndf_encoded = df_encoded.reset_index(drop=True)\n\n# Menggabungkan data ter-encode ke dataframe asli tanpa inplace=True\ndf = pd.concat([df.drop(categorical_features, axis=1), df_encoded], axis=1)\n\n# Menentukan fitur dan target\nfeatures = ['Tinggi (m)', 'Volume_Air (L)', 'Garam_Krosok (kg)', \n            'Molase (ml)', 'Probiotik (ml)', 'Kapur_Dolomit (ml)', \n            'Dimensi (m)'] + list(encoded_feature_names)\n\ntarget = 'Label'\n\nX = df[features].values\ny = df[target].map({'Benar': 1, 'Salah': 0}).values\n\n# Normalisasi fitur\nscaler = MinMaxScaler()\nX_scaled = scaler.fit_transform(X)\njoblib.dump(scaler, 'scaler_bioflok.pkl')\nprint(\"Scaler disimpan sebagai 'scaler_bioflok.pkl'.\")\n\n# ---------------------------------------\n# FUNGSI PEMBANGUNAN MODEL\n# ---------------------------------------\ndef build_model(input_dim, learning_rate=1e-3, l2_reg=1e-5, dropout_rate=0.2):\n    input_layer = Input(shape=(input_dim,))\n    \n    x = Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(l2_reg))(input_layer)\n    x = BatchNormalization()(x)\n    x = Dropout(dropout_rate)(x)\n\n    x = Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(l2_reg))(x)\n    x = BatchNormalization()(x)\n    x = Dropout(dropout_rate)(x)\n\n    x = Dense(32, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(l2_reg))(x)\n    x = BatchNormalization()(x)\n    x = Dropout(dropout_rate)(x)\n\n    output = Dense(1, activation='sigmoid')(x)\n\n    model = Model(inputs=input_layer, outputs=output)\n    model.compile(\n        optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n        loss='binary_crossentropy',\n        metrics=['accuracy']\n    )\n    return model\n\n# ---------------------------------------\n# CROSS-VALIDATION DENGAN STRATIFIEDKFold\n# ---------------------------------------\nkf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\nfold = 1\ncv_accuracies = []\ncv_reports = []\n\nepochs = 100\nbatch_size = 32  # Meningkatkan batch_size untuk efisiensi\n\nfor train_index, test_index in kf.split(X_scaled, y):\n    print(f\"\\n----- Fold {fold} -----\")\n    X_train_fold, X_test_fold = X_scaled[train_index], X_scaled[test_index]\n    y_train_fold, y_test_fold = y[train_index], y[test_index]\n\n    # Handling imbalanced data dengan SMOTE pada data training\n    sm = SMOTE(random_state=42)\n    X_train_fold_res, y_train_fold_res = sm.fit_resample(X_train_fold, y_train_fold)\n    print(f\"Fold {fold}: Sebelum SMOTE: {np.bincount(y_train_fold)}, Setelah SMOTE: {np.bincount(y_train_fold_res)}\")\n\n    # Membangun model baru\n    model = build_model(input_dim=X_train_fold_res.shape[1], learning_rate=1e-3, l2_reg=1e-5, dropout_rate=0.2)\n\n    # Definisi Callbacks dengan ekstensi .keras\n    early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True, verbose=1)\n    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, verbose=1)\n    checkpoint = ModelCheckpoint(\n        filepath=f'best_model_fold_{fold}.keras',  # Menggunakan ekstensi .keras\n        monitor='val_loss',\n        verbose=1,\n        save_best_only=True,\n        save_weights_only=False,\n        mode='min'\n    )\n\n    callbacks = [early_stop, reduce_lr, checkpoint]\n\n    # Melatih model\n    history = model.fit(\n        X_train_fold_res, y_train_fold_res,\n        validation_split=0.2,\n        epochs=epochs,\n        batch_size=batch_size,\n        callbacks=callbacks,\n        verbose=1\n    )\n\n    # Load model terbaik dari fold ini\n    best_model_fold = tf.keras.models.load_model(f'best_model_fold_{fold}.keras')\n\n    # Evaluasi pada data test fold ini\n    eval_res = best_model_fold.evaluate(X_test_fold, y_test_fold, verbose=0)\n    y_pred_prob = best_model_fold.predict(X_test_fold)\n    y_pred_fold = (y_pred_prob.flatten() > 0.5).astype(int)\n\n    acc = accuracy_score(y_test_fold, y_pred_fold)\n    cv_accuracies.append(acc)\n\n    rep = classification_report(y_test_fold, y_pred_fold, output_dict=True)\n    cv_reports.append(rep)\n\n    print(f\"Fold {fold} - Accuracy: {acc:.4f}\")\n    fold += 1\n\n# Rata-rata performa cross-validation\nmean_acc = np.mean(cv_accuracies)\nstd_acc = np.std(cv_accuracies)\nprint(f\"\\nCross-Validation Accuracy: {mean_acc:.4f} Â± {std_acc:.4f}\")\n\n# ---------------------------------------\n# MELATIH MODEL FINAL DAN ANALISIS FITUR DENGAN SHAP (OPSIONAL)\n# ---------------------------------------\n# Membagi data menjadi train dan test final\nX_train_full, X_test_final, y_train_full, y_test_final = train_test_split(\n    X_scaled, y, test_size=0.2, random_state=42, stratify=y)\n\n# Handling imbalanced data dengan SMOTE pada data training full\nsm = SMOTE(random_state=42)\nX_train_full_res, y_train_full_res = sm.fit_resample(X_train_full, y_train_full)\n\n# Membangun dan melatih model final\nfinal_model = build_model(input_dim=X_train_full_res.shape[1], learning_rate=1e-3, l2_reg=1e-5, dropout_rate=0.2)\nearly_stop_final = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True, verbose=1)\nreduce_lr_final = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, verbose=1)\ncheckpoint_final = ModelCheckpoint(\n    filepath='best_final_model.keras',  # Menggunakan ekstensi .keras\n    monitor='val_loss',\n    verbose=1,\n    save_best_only=True,\n    save_weights_only=False,\n    mode='min'\n)\n\ncallbacks_final = [early_stop_final, reduce_lr_final, checkpoint_final]\n\nfinal_history = final_model.fit(\n    X_train_full_res, y_train_full_res,\n    validation_split=0.2,\n    epochs=100,\n    batch_size=32,\n    callbacks=callbacks_final,\n    verbose=1\n)\n\n# Load model terbaik\nbest_final_model = tf.keras.models.load_model('best_final_model.keras')\n\n# Evaluasi pada data test final\ny_pred_final = best_final_model.predict(X_test_final)\ny_pred_final = (y_pred_final.flatten() > 0.5).astype(int)\n\nprint(\"\\nFinal Model Classification Report:\")\nprint(classification_report(y_test_final, y_pred_final))\n\n# SHAP Analysis\n# Pastikan shap terinstall: pip install shap\nimport shap\n\n# Membuat explainer dengan subset data training\nexplainer = shap.DeepExplainer(best_final_model, X_train_full_res[:100])\nshap_values = explainer.shap_values(X_test_final[:50])\n\n# Plot summary\nshap.summary_plot(shap_values, X_test_final[:50], feature_names=features)\nplt.show()\n\n# ---------------------------------------\n# SIMPAN MODEL DAN SCALER\n# ---------------------------------------\nfinal_model.save('final_model_bioflok_adv.keras')  # Menyimpan dengan ekstensi .keras\nprint(\"Model akhir disimpan sebagai 'final_model_bioflok_adv.keras'.\")\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-18T11:24:46.087583Z","iopub.execute_input":"2024-12-18T11:24:46.088125Z"}},"outputs":[],"execution_count":null}]}